# configs/development.yaml
# Development environment configuration

api:
  host: "0.0.0.0"
  port: 8000
  debug: true
  reload: true
  workers: 1
  cors_origins:
    - "http://localhost:3000"
    - "http://localhost:8501"
    - "http://127.0.0.1:8501"

database:
  pool_size: 5
  max_overflow: 10
  pool_pre_ping: true
  echo: false  # Set to true for SQL debugging

redis:
  decode_responses: false
  socket_connect_timeout: 5
  socket_timeout: 5
  max_connections: 10

mlflow:
  experiment_name: "automl_dev"
  artifact_location: "./mlruns"
  registry_uri: "sqlite:///mlflow.db"

langchain:
  verbose: true
  cache: true
  callbacks: true

langraph:
  checkpoint_interval: 5
  max_iterations: 50
  memory_type: "redis"
  debug: true

agents:
  llm_model: "gpt-4"
  temperature: 0.1
  max_tokens: 2000
  max_retries: 3
  timeout_seconds: 300
  request_timeout: 60

features:
  enable_debug_mode: true
  enable_auto_mode: true
  enable_interactive_mode: true
  max_upload_size_mb: 100
  max_concurrent_experiments: 5
  allow_anonymous_access: false

preprocessing:
  default_imputation_strategy: "mean"
  default_scaling_method: "standard"
  handle_outliers: true
  outlier_threshold: 1.5
  drop_high_cardinality_threshold: 0.95
  drop_low_variance_threshold: 0.01

model_training:
  cv_folds: 5
  test_size: 0.2
  random_state: 42
  n_jobs: -1  # Use all cores
  early_stopping: true
  early_stopping_rounds: 10

optimization:
  n_trials: 100
  timeout: 3600  # 1 hour
  n_jobs: 1  # Parallel trials
  sampler: "TPESampler"
  pruner: "MedianPruner"
  direction: "maximize"  # For accuracy

logging:
  level: "INFO"
  format: "json"
  file: "logs/automl_dev.log"
  max_size_mb: 100
  backup_count: 5
  
security:
  jwt_expiration_hours: 24
  password_min_length: 8
  max_login_attempts: 5
  lockout_duration_minutes: 15

monitoring:
  enable_metrics: true
  metrics_port: 9090
  health_check_interval: 30
  performance_tracking: true